/**
 * This file was auto-generated by Fern from our API Definition.
 */
package com.cohere.api.resources.v2.requests;

import com.cohere.api.core.ObjectMappers;
import com.cohere.api.resources.v2.types.V2ChatStreamRequestDocumentsItem;
import com.cohere.api.resources.v2.types.V2ChatStreamRequestSafetyMode;
import com.cohere.api.resources.v2.types.V2ChatStreamRequestToolChoice;
import com.cohere.api.types.ChatMessageV2;
import com.cohere.api.types.CitationOptions;
import com.cohere.api.types.ResponseFormatV2;
import com.cohere.api.types.Thinking;
import com.cohere.api.types.ToolV2;
import com.fasterxml.jackson.annotation.JsonAnyGetter;
import com.fasterxml.jackson.annotation.JsonAnySetter;
import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonSetter;
import com.fasterxml.jackson.annotation.Nulls;
import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import org.jetbrains.annotations.NotNull;

@JsonInclude(JsonInclude.Include.NON_ABSENT)
@JsonDeserialize(builder = V2ChatStreamRequest.Builder.class)
public final class V2ChatStreamRequest {
    private final String model;

    private final List<ChatMessageV2> messages;

    private final Optional<List<ToolV2>> tools;

    private final Optional<Boolean> strictTools;

    private final Optional<List<V2ChatStreamRequestDocumentsItem>> documents;

    private final Optional<CitationOptions> citationOptions;

    private final Optional<ResponseFormatV2> responseFormat;

    private final Optional<V2ChatStreamRequestSafetyMode> safetyMode;

    private final Optional<Integer> maxTokens;

    private final Optional<List<String>> stopSequences;

    private final Optional<Float> temperature;

    private final Optional<Integer> seed;

    private final Optional<Float> frequencyPenalty;

    private final Optional<Float> presencePenalty;

    private final Optional<Integer> k;

    private final Optional<Float> p;

    private final Optional<Boolean> logprobs;

    private final Optional<V2ChatStreamRequestToolChoice> toolChoice;

    private final Optional<Thinking> thinking;

    private final Map<String, Object> additionalProperties;

    private V2ChatStreamRequest(
            String model,
            List<ChatMessageV2> messages,
            Optional<List<ToolV2>> tools,
            Optional<Boolean> strictTools,
            Optional<List<V2ChatStreamRequestDocumentsItem>> documents,
            Optional<CitationOptions> citationOptions,
            Optional<ResponseFormatV2> responseFormat,
            Optional<V2ChatStreamRequestSafetyMode> safetyMode,
            Optional<Integer> maxTokens,
            Optional<List<String>> stopSequences,
            Optional<Float> temperature,
            Optional<Integer> seed,
            Optional<Float> frequencyPenalty,
            Optional<Float> presencePenalty,
            Optional<Integer> k,
            Optional<Float> p,
            Optional<Boolean> logprobs,
            Optional<V2ChatStreamRequestToolChoice> toolChoice,
            Optional<Thinking> thinking,
            Map<String, Object> additionalProperties) {
        this.model = model;
        this.messages = messages;
        this.tools = tools;
        this.strictTools = strictTools;
        this.documents = documents;
        this.citationOptions = citationOptions;
        this.responseFormat = responseFormat;
        this.safetyMode = safetyMode;
        this.maxTokens = maxTokens;
        this.stopSequences = stopSequences;
        this.temperature = temperature;
        this.seed = seed;
        this.frequencyPenalty = frequencyPenalty;
        this.presencePenalty = presencePenalty;
        this.k = k;
        this.p = p;
        this.logprobs = logprobs;
        this.toolChoice = toolChoice;
        this.thinking = thinking;
        this.additionalProperties = additionalProperties;
    }

    /**
     * @return Defaults to <code>false</code>.
     * <p>When <code>true</code>, the response will be a SSE stream of events.</p>
     * <p>Streaming is beneficial for user interfaces that render the contents of the response piece by piece, as it gets generated.</p>
     */
    @JsonProperty("stream")
    public Boolean getStream() {
        return true;
    }

    /**
     * @return The name of a compatible <a href="https://docs.cohere.com/v2/docs/models">Cohere model</a>.
     */
    @JsonProperty("model")
    public String getModel() {
        return model;
    }

    @JsonProperty("messages")
    public List<ChatMessageV2> getMessages() {
        return messages;
    }

    /**
     * @return A list of tools (functions) available to the model. The model response may contain 'tool_calls' to the specified tools.
     * <p>Learn more in the <a href="https://docs.cohere.com/docs/tools">Tool Use guide</a>.</p>
     */
    @JsonProperty("tools")
    public Optional<List<ToolV2>> getTools() {
        return tools;
    }

    /**
     * @return When set to <code>true</code>, tool calls in the Assistant message will be forced to follow the tool definition strictly. Learn more in the <a href="https://docs.cohere.com/docs/structured-outputs-json#structured-outputs-tools">Structured Outputs (Tools) guide</a>.
     * <p><strong>Note</strong>: The first few requests with a new set of tools will take longer to process.</p>
     */
    @JsonProperty("strict_tools")
    public Optional<Boolean> getStrictTools() {
        return strictTools;
    }

    /**
     * @return A list of relevant documents that the model can cite to generate a more accurate reply. Each document is either a string or document object with content and metadata.
     */
    @JsonProperty("documents")
    public Optional<List<V2ChatStreamRequestDocumentsItem>> getDocuments() {
        return documents;
    }

    @JsonProperty("citation_options")
    public Optional<CitationOptions> getCitationOptions() {
        return citationOptions;
    }

    @JsonProperty("response_format")
    public Optional<ResponseFormatV2> getResponseFormat() {
        return responseFormat;
    }

    /**
     * @return Used to select the <a href="https://docs.cohere.com/v2/docs/safety-modes">safety instruction</a> inserted into the prompt. Defaults to <code>CONTEXTUAL</code>.
     * When <code>OFF</code> is specified, the safety instruction will be omitted.
     * <p>Safety modes are not yet configurable in combination with <code>tools</code> and <code>documents</code> parameters.</p>
     * <p><strong>Note</strong>: This parameter is only compatible newer Cohere models, starting with <a href="https://docs.cohere.com/docs/command-r#august-2024-release">Command R 08-2024</a> and <a href="https://docs.cohere.com/docs/command-r-plus#august-2024-release">Command R+ 08-2024</a>.</p>
     * <p><strong>Note</strong>: <code>command-r7b-12-2024</code> and newer models only support <code>&quot;CONTEXTUAL&quot;</code> and <code>&quot;STRICT&quot;</code> modes.</p>
     */
    @JsonProperty("safety_mode")
    public Optional<V2ChatStreamRequestSafetyMode> getSafetyMode() {
        return safetyMode;
    }

    /**
     * @return The maximum number of output tokens the model will generate in the response. If not set, <code>max_tokens</code> defaults to the model's maximum output token limit. You can find the maximum output token limits for each model in the <a href="https://docs.cohere.com/docs/models">model documentation</a>.
     * <p><strong>Note</strong>: Setting a low value may result in incomplete generations. In such cases, the <code>finish_reason</code> field in the response will be set to <code>&quot;MAX_TOKENS&quot;</code>.</p>
     * <p><strong>Note</strong>: If <code>max_tokens</code> is set higher than the model's maximum output token limit, the generation will be capped at that model-specific maximum limit.</p>
     */
    @JsonProperty("max_tokens")
    public Optional<Integer> getMaxTokens() {
        return maxTokens;
    }

    /**
     * @return A list of up to 5 strings that the model will use to stop generation. If the model generates a string that matches any of the strings in the list, it will stop generating tokens and return the generated text up to that point not including the stop sequence.
     */
    @JsonProperty("stop_sequences")
    public Optional<List<String>> getStopSequences() {
        return stopSequences;
    }

    /**
     * @return Defaults to <code>0.3</code>.
     * <p>A non-negative float that tunes the degree of randomness in generation. Lower temperatures mean less random generations, and higher temperatures mean more random generations.</p>
     * <p>Randomness can be further maximized by increasing the  value of the <code>p</code> parameter.</p>
     */
    @JsonProperty("temperature")
    public Optional<Float> getTemperature() {
        return temperature;
    }

    /**
     * @return If specified, the backend will make a best effort to sample tokens
     * deterministically, such that repeated requests with the same
     * seed and parameters should return the same result. However,
     * determinism cannot be totally guaranteed.
     */
    @JsonProperty("seed")
    public Optional<Integer> getSeed() {
        return seed;
    }

    /**
     * @return Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.
     * Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.
     */
    @JsonProperty("frequency_penalty")
    public Optional<Float> getFrequencyPenalty() {
        return frequencyPenalty;
    }

    /**
     * @return Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.
     * Used to reduce repetitiveness of generated tokens. Similar to <code>frequency_penalty</code>, except that this penalty is applied equally to all tokens that have already appeared, regardless of their exact frequencies.
     */
    @JsonProperty("presence_penalty")
    public Optional<Float> getPresencePenalty() {
        return presencePenalty;
    }

    /**
     * @return Ensures that only the top <code>k</code> most likely tokens are considered for generation at each step. When <code>k</code> is set to <code>0</code>, k-sampling is disabled.
     * Defaults to <code>0</code>, min value of <code>0</code>, max value of <code>500</code>.
     */
    @JsonProperty("k")
    public Optional<Integer> getK() {
        return k;
    }

    /**
     * @return Ensures that only the most likely tokens, with total probability mass of <code>p</code>, are considered for generation at each step. If both <code>k</code> and <code>p</code> are enabled, <code>p</code> acts after <code>k</code>.
     * Defaults to <code>0.75</code>. min value of <code>0.01</code>, max value of <code>0.99</code>.
     */
    @JsonProperty("p")
    public Optional<Float> getP() {
        return p;
    }

    /**
     * @return Defaults to <code>false</code>. When set to <code>true</code>, the log probabilities of the generated tokens will be included in the response.
     */
    @JsonProperty("logprobs")
    public Optional<Boolean> getLogprobs() {
        return logprobs;
    }

    /**
     * @return Used to control whether or not the model will be forced to use a tool when answering. When <code>REQUIRED</code> is specified, the model will be forced to use at least one of the user-defined tools, and the <code>tools</code> parameter must be passed in the request.
     * When <code>NONE</code> is specified, the model will be forced <strong>not</strong> to use one of the specified tools, and give a direct response.
     * If tool_choice isn't specified, then the model is free to choose whether to use the specified tools or not.
     * <p><strong>Note</strong>: This parameter is only compatible with models <a href="https://docs.cohere.com/v2/docs/command-r7b">Command-r7b</a> and newer.</p>
     */
    @JsonProperty("tool_choice")
    public Optional<V2ChatStreamRequestToolChoice> getToolChoice() {
        return toolChoice;
    }

    @JsonProperty("thinking")
    public Optional<Thinking> getThinking() {
        return thinking;
    }

    @java.lang.Override
    public boolean equals(Object other) {
        if (this == other) return true;
        return other instanceof V2ChatStreamRequest && equalTo((V2ChatStreamRequest) other);
    }

    @JsonAnyGetter
    public Map<String, Object> getAdditionalProperties() {
        return this.additionalProperties;
    }

    private boolean equalTo(V2ChatStreamRequest other) {
        return model.equals(other.model)
                && messages.equals(other.messages)
                && tools.equals(other.tools)
                && strictTools.equals(other.strictTools)
                && documents.equals(other.documents)
                && citationOptions.equals(other.citationOptions)
                && responseFormat.equals(other.responseFormat)
                && safetyMode.equals(other.safetyMode)
                && maxTokens.equals(other.maxTokens)
                && stopSequences.equals(other.stopSequences)
                && temperature.equals(other.temperature)
                && seed.equals(other.seed)
                && frequencyPenalty.equals(other.frequencyPenalty)
                && presencePenalty.equals(other.presencePenalty)
                && k.equals(other.k)
                && p.equals(other.p)
                && logprobs.equals(other.logprobs)
                && toolChoice.equals(other.toolChoice)
                && thinking.equals(other.thinking);
    }

    @java.lang.Override
    public int hashCode() {
        return Objects.hash(
                this.model,
                this.messages,
                this.tools,
                this.strictTools,
                this.documents,
                this.citationOptions,
                this.responseFormat,
                this.safetyMode,
                this.maxTokens,
                this.stopSequences,
                this.temperature,
                this.seed,
                this.frequencyPenalty,
                this.presencePenalty,
                this.k,
                this.p,
                this.logprobs,
                this.toolChoice,
                this.thinking);
    }

    @java.lang.Override
    public String toString() {
        return ObjectMappers.stringify(this);
    }

    public static ModelStage builder() {
        return new Builder();
    }

    public interface ModelStage {
        /**
         * <p>The name of a compatible <a href="https://docs.cohere.com/v2/docs/models">Cohere model</a>.</p>
         */
        _FinalStage model(@NotNull String model);

        Builder from(V2ChatStreamRequest other);
    }

    public interface _FinalStage {
        V2ChatStreamRequest build();

        _FinalStage messages(List<ChatMessageV2> messages);

        _FinalStage addMessages(ChatMessageV2 messages);

        _FinalStage addAllMessages(List<ChatMessageV2> messages);

        /**
         * <p>A list of tools (functions) available to the model. The model response may contain 'tool_calls' to the specified tools.</p>
         * <p>Learn more in the <a href="https://docs.cohere.com/docs/tools">Tool Use guide</a>.</p>
         */
        _FinalStage tools(Optional<List<ToolV2>> tools);

        _FinalStage tools(List<ToolV2> tools);

        /**
         * <p>When set to <code>true</code>, tool calls in the Assistant message will be forced to follow the tool definition strictly. Learn more in the <a href="https://docs.cohere.com/docs/structured-outputs-json#structured-outputs-tools">Structured Outputs (Tools) guide</a>.</p>
         * <p><strong>Note</strong>: The first few requests with a new set of tools will take longer to process.</p>
         */
        _FinalStage strictTools(Optional<Boolean> strictTools);

        _FinalStage strictTools(Boolean strictTools);

        /**
         * <p>A list of relevant documents that the model can cite to generate a more accurate reply. Each document is either a string or document object with content and metadata.</p>
         */
        _FinalStage documents(Optional<List<V2ChatStreamRequestDocumentsItem>> documents);

        _FinalStage documents(List<V2ChatStreamRequestDocumentsItem> documents);

        _FinalStage citationOptions(Optional<CitationOptions> citationOptions);

        _FinalStage citationOptions(CitationOptions citationOptions);

        _FinalStage responseFormat(Optional<ResponseFormatV2> responseFormat);

        _FinalStage responseFormat(ResponseFormatV2 responseFormat);

        /**
         * <p>Used to select the <a href="https://docs.cohere.com/v2/docs/safety-modes">safety instruction</a> inserted into the prompt. Defaults to <code>CONTEXTUAL</code>.
         * When <code>OFF</code> is specified, the safety instruction will be omitted.</p>
         * <p>Safety modes are not yet configurable in combination with <code>tools</code> and <code>documents</code> parameters.</p>
         * <p><strong>Note</strong>: This parameter is only compatible newer Cohere models, starting with <a href="https://docs.cohere.com/docs/command-r#august-2024-release">Command R 08-2024</a> and <a href="https://docs.cohere.com/docs/command-r-plus#august-2024-release">Command R+ 08-2024</a>.</p>
         * <p><strong>Note</strong>: <code>command-r7b-12-2024</code> and newer models only support <code>&quot;CONTEXTUAL&quot;</code> and <code>&quot;STRICT&quot;</code> modes.</p>
         */
        _FinalStage safetyMode(Optional<V2ChatStreamRequestSafetyMode> safetyMode);

        _FinalStage safetyMode(V2ChatStreamRequestSafetyMode safetyMode);

        /**
         * <p>The maximum number of output tokens the model will generate in the response. If not set, <code>max_tokens</code> defaults to the model's maximum output token limit. You can find the maximum output token limits for each model in the <a href="https://docs.cohere.com/docs/models">model documentation</a>.</p>
         * <p><strong>Note</strong>: Setting a low value may result in incomplete generations. In such cases, the <code>finish_reason</code> field in the response will be set to <code>&quot;MAX_TOKENS&quot;</code>.</p>
         * <p><strong>Note</strong>: If <code>max_tokens</code> is set higher than the model's maximum output token limit, the generation will be capped at that model-specific maximum limit.</p>
         */
        _FinalStage maxTokens(Optional<Integer> maxTokens);

        _FinalStage maxTokens(Integer maxTokens);

        /**
         * <p>A list of up to 5 strings that the model will use to stop generation. If the model generates a string that matches any of the strings in the list, it will stop generating tokens and return the generated text up to that point not including the stop sequence.</p>
         */
        _FinalStage stopSequences(Optional<List<String>> stopSequences);

        _FinalStage stopSequences(List<String> stopSequences);

        /**
         * <p>Defaults to <code>0.3</code>.</p>
         * <p>A non-negative float that tunes the degree of randomness in generation. Lower temperatures mean less random generations, and higher temperatures mean more random generations.</p>
         * <p>Randomness can be further maximized by increasing the  value of the <code>p</code> parameter.</p>
         */
        _FinalStage temperature(Optional<Float> temperature);

        _FinalStage temperature(Float temperature);

        /**
         * <p>If specified, the backend will make a best effort to sample tokens
         * deterministically, such that repeated requests with the same
         * seed and parameters should return the same result. However,
         * determinism cannot be totally guaranteed.</p>
         */
        _FinalStage seed(Optional<Integer> seed);

        _FinalStage seed(Integer seed);

        /**
         * <p>Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.
         * Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.</p>
         */
        _FinalStage frequencyPenalty(Optional<Float> frequencyPenalty);

        _FinalStage frequencyPenalty(Float frequencyPenalty);

        /**
         * <p>Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.
         * Used to reduce repetitiveness of generated tokens. Similar to <code>frequency_penalty</code>, except that this penalty is applied equally to all tokens that have already appeared, regardless of their exact frequencies.</p>
         */
        _FinalStage presencePenalty(Optional<Float> presencePenalty);

        _FinalStage presencePenalty(Float presencePenalty);

        /**
         * <p>Ensures that only the top <code>k</code> most likely tokens are considered for generation at each step. When <code>k</code> is set to <code>0</code>, k-sampling is disabled.
         * Defaults to <code>0</code>, min value of <code>0</code>, max value of <code>500</code>.</p>
         */
        _FinalStage k(Optional<Integer> k);

        _FinalStage k(Integer k);

        /**
         * <p>Ensures that only the most likely tokens, with total probability mass of <code>p</code>, are considered for generation at each step. If both <code>k</code> and <code>p</code> are enabled, <code>p</code> acts after <code>k</code>.
         * Defaults to <code>0.75</code>. min value of <code>0.01</code>, max value of <code>0.99</code>.</p>
         */
        _FinalStage p(Optional<Float> p);

        _FinalStage p(Float p);

        /**
         * <p>Defaults to <code>false</code>. When set to <code>true</code>, the log probabilities of the generated tokens will be included in the response.</p>
         */
        _FinalStage logprobs(Optional<Boolean> logprobs);

        _FinalStage logprobs(Boolean logprobs);

        /**
         * <p>Used to control whether or not the model will be forced to use a tool when answering. When <code>REQUIRED</code> is specified, the model will be forced to use at least one of the user-defined tools, and the <code>tools</code> parameter must be passed in the request.
         * When <code>NONE</code> is specified, the model will be forced <strong>not</strong> to use one of the specified tools, and give a direct response.
         * If tool_choice isn't specified, then the model is free to choose whether to use the specified tools or not.</p>
         * <p><strong>Note</strong>: This parameter is only compatible with models <a href="https://docs.cohere.com/v2/docs/command-r7b">Command-r7b</a> and newer.</p>
         */
        _FinalStage toolChoice(Optional<V2ChatStreamRequestToolChoice> toolChoice);

        _FinalStage toolChoice(V2ChatStreamRequestToolChoice toolChoice);

        _FinalStage thinking(Optional<Thinking> thinking);

        _FinalStage thinking(Thinking thinking);
    }

    @JsonIgnoreProperties(ignoreUnknown = true)
    public static final class Builder implements ModelStage, _FinalStage {
        private String model;

        private Optional<Thinking> thinking = Optional.empty();

        private Optional<V2ChatStreamRequestToolChoice> toolChoice = Optional.empty();

        private Optional<Boolean> logprobs = Optional.empty();

        private Optional<Float> p = Optional.empty();

        private Optional<Integer> k = Optional.empty();

        private Optional<Float> presencePenalty = Optional.empty();

        private Optional<Float> frequencyPenalty = Optional.empty();

        private Optional<Integer> seed = Optional.empty();

        private Optional<Float> temperature = Optional.empty();

        private Optional<List<String>> stopSequences = Optional.empty();

        private Optional<Integer> maxTokens = Optional.empty();

        private Optional<V2ChatStreamRequestSafetyMode> safetyMode = Optional.empty();

        private Optional<ResponseFormatV2> responseFormat = Optional.empty();

        private Optional<CitationOptions> citationOptions = Optional.empty();

        private Optional<List<V2ChatStreamRequestDocumentsItem>> documents = Optional.empty();

        private Optional<Boolean> strictTools = Optional.empty();

        private Optional<List<ToolV2>> tools = Optional.empty();

        private List<ChatMessageV2> messages = new ArrayList<>();

        @JsonAnySetter
        private Map<String, Object> additionalProperties = new HashMap<>();

        private Builder() {}

        @java.lang.Override
        public Builder from(V2ChatStreamRequest other) {
            model(other.getModel());
            messages(other.getMessages());
            tools(other.getTools());
            strictTools(other.getStrictTools());
            documents(other.getDocuments());
            citationOptions(other.getCitationOptions());
            responseFormat(other.getResponseFormat());
            safetyMode(other.getSafetyMode());
            maxTokens(other.getMaxTokens());
            stopSequences(other.getStopSequences());
            temperature(other.getTemperature());
            seed(other.getSeed());
            frequencyPenalty(other.getFrequencyPenalty());
            presencePenalty(other.getPresencePenalty());
            k(other.getK());
            p(other.getP());
            logprobs(other.getLogprobs());
            toolChoice(other.getToolChoice());
            thinking(other.getThinking());
            return this;
        }

        /**
         * <p>The name of a compatible <a href="https://docs.cohere.com/v2/docs/models">Cohere model</a>.</p>
         * <p>The name of a compatible <a href="https://docs.cohere.com/v2/docs/models">Cohere model</a>.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        @JsonSetter("model")
        public _FinalStage model(@NotNull String model) {
            this.model = Objects.requireNonNull(model, "model must not be null");
            return this;
        }

        @java.lang.Override
        public _FinalStage thinking(Thinking thinking) {
            this.thinking = Optional.ofNullable(thinking);
            return this;
        }

        @java.lang.Override
        @JsonSetter(value = "thinking", nulls = Nulls.SKIP)
        public _FinalStage thinking(Optional<Thinking> thinking) {
            this.thinking = thinking;
            return this;
        }

        /**
         * <p>Used to control whether or not the model will be forced to use a tool when answering. When <code>REQUIRED</code> is specified, the model will be forced to use at least one of the user-defined tools, and the <code>tools</code> parameter must be passed in the request.
         * When <code>NONE</code> is specified, the model will be forced <strong>not</strong> to use one of the specified tools, and give a direct response.
         * If tool_choice isn't specified, then the model is free to choose whether to use the specified tools or not.</p>
         * <p><strong>Note</strong>: This parameter is only compatible with models <a href="https://docs.cohere.com/v2/docs/command-r7b">Command-r7b</a> and newer.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage toolChoice(V2ChatStreamRequestToolChoice toolChoice) {
            this.toolChoice = Optional.ofNullable(toolChoice);
            return this;
        }

        /**
         * <p>Used to control whether or not the model will be forced to use a tool when answering. When <code>REQUIRED</code> is specified, the model will be forced to use at least one of the user-defined tools, and the <code>tools</code> parameter must be passed in the request.
         * When <code>NONE</code> is specified, the model will be forced <strong>not</strong> to use one of the specified tools, and give a direct response.
         * If tool_choice isn't specified, then the model is free to choose whether to use the specified tools or not.</p>
         * <p><strong>Note</strong>: This parameter is only compatible with models <a href="https://docs.cohere.com/v2/docs/command-r7b">Command-r7b</a> and newer.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "tool_choice", nulls = Nulls.SKIP)
        public _FinalStage toolChoice(Optional<V2ChatStreamRequestToolChoice> toolChoice) {
            this.toolChoice = toolChoice;
            return this;
        }

        /**
         * <p>Defaults to <code>false</code>. When set to <code>true</code>, the log probabilities of the generated tokens will be included in the response.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage logprobs(Boolean logprobs) {
            this.logprobs = Optional.ofNullable(logprobs);
            return this;
        }

        /**
         * <p>Defaults to <code>false</code>. When set to <code>true</code>, the log probabilities of the generated tokens will be included in the response.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "logprobs", nulls = Nulls.SKIP)
        public _FinalStage logprobs(Optional<Boolean> logprobs) {
            this.logprobs = logprobs;
            return this;
        }

        /**
         * <p>Ensures that only the most likely tokens, with total probability mass of <code>p</code>, are considered for generation at each step. If both <code>k</code> and <code>p</code> are enabled, <code>p</code> acts after <code>k</code>.
         * Defaults to <code>0.75</code>. min value of <code>0.01</code>, max value of <code>0.99</code>.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage p(Float p) {
            this.p = Optional.ofNullable(p);
            return this;
        }

        /**
         * <p>Ensures that only the most likely tokens, with total probability mass of <code>p</code>, are considered for generation at each step. If both <code>k</code> and <code>p</code> are enabled, <code>p</code> acts after <code>k</code>.
         * Defaults to <code>0.75</code>. min value of <code>0.01</code>, max value of <code>0.99</code>.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "p", nulls = Nulls.SKIP)
        public _FinalStage p(Optional<Float> p) {
            this.p = p;
            return this;
        }

        /**
         * <p>Ensures that only the top <code>k</code> most likely tokens are considered for generation at each step. When <code>k</code> is set to <code>0</code>, k-sampling is disabled.
         * Defaults to <code>0</code>, min value of <code>0</code>, max value of <code>500</code>.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage k(Integer k) {
            this.k = Optional.ofNullable(k);
            return this;
        }

        /**
         * <p>Ensures that only the top <code>k</code> most likely tokens are considered for generation at each step. When <code>k</code> is set to <code>0</code>, k-sampling is disabled.
         * Defaults to <code>0</code>, min value of <code>0</code>, max value of <code>500</code>.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "k", nulls = Nulls.SKIP)
        public _FinalStage k(Optional<Integer> k) {
            this.k = k;
            return this;
        }

        /**
         * <p>Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.
         * Used to reduce repetitiveness of generated tokens. Similar to <code>frequency_penalty</code>, except that this penalty is applied equally to all tokens that have already appeared, regardless of their exact frequencies.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage presencePenalty(Float presencePenalty) {
            this.presencePenalty = Optional.ofNullable(presencePenalty);
            return this;
        }

        /**
         * <p>Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.
         * Used to reduce repetitiveness of generated tokens. Similar to <code>frequency_penalty</code>, except that this penalty is applied equally to all tokens that have already appeared, regardless of their exact frequencies.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "presence_penalty", nulls = Nulls.SKIP)
        public _FinalStage presencePenalty(Optional<Float> presencePenalty) {
            this.presencePenalty = presencePenalty;
            return this;
        }

        /**
         * <p>Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.
         * Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage frequencyPenalty(Float frequencyPenalty) {
            this.frequencyPenalty = Optional.ofNullable(frequencyPenalty);
            return this;
        }

        /**
         * <p>Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.
         * Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "frequency_penalty", nulls = Nulls.SKIP)
        public _FinalStage frequencyPenalty(Optional<Float> frequencyPenalty) {
            this.frequencyPenalty = frequencyPenalty;
            return this;
        }

        /**
         * <p>If specified, the backend will make a best effort to sample tokens
         * deterministically, such that repeated requests with the same
         * seed and parameters should return the same result. However,
         * determinism cannot be totally guaranteed.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage seed(Integer seed) {
            this.seed = Optional.ofNullable(seed);
            return this;
        }

        /**
         * <p>If specified, the backend will make a best effort to sample tokens
         * deterministically, such that repeated requests with the same
         * seed and parameters should return the same result. However,
         * determinism cannot be totally guaranteed.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "seed", nulls = Nulls.SKIP)
        public _FinalStage seed(Optional<Integer> seed) {
            this.seed = seed;
            return this;
        }

        /**
         * <p>Defaults to <code>0.3</code>.</p>
         * <p>A non-negative float that tunes the degree of randomness in generation. Lower temperatures mean less random generations, and higher temperatures mean more random generations.</p>
         * <p>Randomness can be further maximized by increasing the  value of the <code>p</code> parameter.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage temperature(Float temperature) {
            this.temperature = Optional.ofNullable(temperature);
            return this;
        }

        /**
         * <p>Defaults to <code>0.3</code>.</p>
         * <p>A non-negative float that tunes the degree of randomness in generation. Lower temperatures mean less random generations, and higher temperatures mean more random generations.</p>
         * <p>Randomness can be further maximized by increasing the  value of the <code>p</code> parameter.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "temperature", nulls = Nulls.SKIP)
        public _FinalStage temperature(Optional<Float> temperature) {
            this.temperature = temperature;
            return this;
        }

        /**
         * <p>A list of up to 5 strings that the model will use to stop generation. If the model generates a string that matches any of the strings in the list, it will stop generating tokens and return the generated text up to that point not including the stop sequence.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage stopSequences(List<String> stopSequences) {
            this.stopSequences = Optional.ofNullable(stopSequences);
            return this;
        }

        /**
         * <p>A list of up to 5 strings that the model will use to stop generation. If the model generates a string that matches any of the strings in the list, it will stop generating tokens and return the generated text up to that point not including the stop sequence.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "stop_sequences", nulls = Nulls.SKIP)
        public _FinalStage stopSequences(Optional<List<String>> stopSequences) {
            this.stopSequences = stopSequences;
            return this;
        }

        /**
         * <p>The maximum number of output tokens the model will generate in the response. If not set, <code>max_tokens</code> defaults to the model's maximum output token limit. You can find the maximum output token limits for each model in the <a href="https://docs.cohere.com/docs/models">model documentation</a>.</p>
         * <p><strong>Note</strong>: Setting a low value may result in incomplete generations. In such cases, the <code>finish_reason</code> field in the response will be set to <code>&quot;MAX_TOKENS&quot;</code>.</p>
         * <p><strong>Note</strong>: If <code>max_tokens</code> is set higher than the model's maximum output token limit, the generation will be capped at that model-specific maximum limit.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage maxTokens(Integer maxTokens) {
            this.maxTokens = Optional.ofNullable(maxTokens);
            return this;
        }

        /**
         * <p>The maximum number of output tokens the model will generate in the response. If not set, <code>max_tokens</code> defaults to the model's maximum output token limit. You can find the maximum output token limits for each model in the <a href="https://docs.cohere.com/docs/models">model documentation</a>.</p>
         * <p><strong>Note</strong>: Setting a low value may result in incomplete generations. In such cases, the <code>finish_reason</code> field in the response will be set to <code>&quot;MAX_TOKENS&quot;</code>.</p>
         * <p><strong>Note</strong>: If <code>max_tokens</code> is set higher than the model's maximum output token limit, the generation will be capped at that model-specific maximum limit.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "max_tokens", nulls = Nulls.SKIP)
        public _FinalStage maxTokens(Optional<Integer> maxTokens) {
            this.maxTokens = maxTokens;
            return this;
        }

        /**
         * <p>Used to select the <a href="https://docs.cohere.com/v2/docs/safety-modes">safety instruction</a> inserted into the prompt. Defaults to <code>CONTEXTUAL</code>.
         * When <code>OFF</code> is specified, the safety instruction will be omitted.</p>
         * <p>Safety modes are not yet configurable in combination with <code>tools</code> and <code>documents</code> parameters.</p>
         * <p><strong>Note</strong>: This parameter is only compatible newer Cohere models, starting with <a href="https://docs.cohere.com/docs/command-r#august-2024-release">Command R 08-2024</a> and <a href="https://docs.cohere.com/docs/command-r-plus#august-2024-release">Command R+ 08-2024</a>.</p>
         * <p><strong>Note</strong>: <code>command-r7b-12-2024</code> and newer models only support <code>&quot;CONTEXTUAL&quot;</code> and <code>&quot;STRICT&quot;</code> modes.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage safetyMode(V2ChatStreamRequestSafetyMode safetyMode) {
            this.safetyMode = Optional.ofNullable(safetyMode);
            return this;
        }

        /**
         * <p>Used to select the <a href="https://docs.cohere.com/v2/docs/safety-modes">safety instruction</a> inserted into the prompt. Defaults to <code>CONTEXTUAL</code>.
         * When <code>OFF</code> is specified, the safety instruction will be omitted.</p>
         * <p>Safety modes are not yet configurable in combination with <code>tools</code> and <code>documents</code> parameters.</p>
         * <p><strong>Note</strong>: This parameter is only compatible newer Cohere models, starting with <a href="https://docs.cohere.com/docs/command-r#august-2024-release">Command R 08-2024</a> and <a href="https://docs.cohere.com/docs/command-r-plus#august-2024-release">Command R+ 08-2024</a>.</p>
         * <p><strong>Note</strong>: <code>command-r7b-12-2024</code> and newer models only support <code>&quot;CONTEXTUAL&quot;</code> and <code>&quot;STRICT&quot;</code> modes.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "safety_mode", nulls = Nulls.SKIP)
        public _FinalStage safetyMode(Optional<V2ChatStreamRequestSafetyMode> safetyMode) {
            this.safetyMode = safetyMode;
            return this;
        }

        @java.lang.Override
        public _FinalStage responseFormat(ResponseFormatV2 responseFormat) {
            this.responseFormat = Optional.ofNullable(responseFormat);
            return this;
        }

        @java.lang.Override
        @JsonSetter(value = "response_format", nulls = Nulls.SKIP)
        public _FinalStage responseFormat(Optional<ResponseFormatV2> responseFormat) {
            this.responseFormat = responseFormat;
            return this;
        }

        @java.lang.Override
        public _FinalStage citationOptions(CitationOptions citationOptions) {
            this.citationOptions = Optional.ofNullable(citationOptions);
            return this;
        }

        @java.lang.Override
        @JsonSetter(value = "citation_options", nulls = Nulls.SKIP)
        public _FinalStage citationOptions(Optional<CitationOptions> citationOptions) {
            this.citationOptions = citationOptions;
            return this;
        }

        /**
         * <p>A list of relevant documents that the model can cite to generate a more accurate reply. Each document is either a string or document object with content and metadata.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage documents(List<V2ChatStreamRequestDocumentsItem> documents) {
            this.documents = Optional.ofNullable(documents);
            return this;
        }

        /**
         * <p>A list of relevant documents that the model can cite to generate a more accurate reply. Each document is either a string or document object with content and metadata.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "documents", nulls = Nulls.SKIP)
        public _FinalStage documents(Optional<List<V2ChatStreamRequestDocumentsItem>> documents) {
            this.documents = documents;
            return this;
        }

        /**
         * <p>When set to <code>true</code>, tool calls in the Assistant message will be forced to follow the tool definition strictly. Learn more in the <a href="https://docs.cohere.com/docs/structured-outputs-json#structured-outputs-tools">Structured Outputs (Tools) guide</a>.</p>
         * <p><strong>Note</strong>: The first few requests with a new set of tools will take longer to process.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage strictTools(Boolean strictTools) {
            this.strictTools = Optional.ofNullable(strictTools);
            return this;
        }

        /**
         * <p>When set to <code>true</code>, tool calls in the Assistant message will be forced to follow the tool definition strictly. Learn more in the <a href="https://docs.cohere.com/docs/structured-outputs-json#structured-outputs-tools">Structured Outputs (Tools) guide</a>.</p>
         * <p><strong>Note</strong>: The first few requests with a new set of tools will take longer to process.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "strict_tools", nulls = Nulls.SKIP)
        public _FinalStage strictTools(Optional<Boolean> strictTools) {
            this.strictTools = strictTools;
            return this;
        }

        /**
         * <p>A list of tools (functions) available to the model. The model response may contain 'tool_calls' to the specified tools.</p>
         * <p>Learn more in the <a href="https://docs.cohere.com/docs/tools">Tool Use guide</a>.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage tools(List<ToolV2> tools) {
            this.tools = Optional.ofNullable(tools);
            return this;
        }

        /**
         * <p>A list of tools (functions) available to the model. The model response may contain 'tool_calls' to the specified tools.</p>
         * <p>Learn more in the <a href="https://docs.cohere.com/docs/tools">Tool Use guide</a>.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "tools", nulls = Nulls.SKIP)
        public _FinalStage tools(Optional<List<ToolV2>> tools) {
            this.tools = tools;
            return this;
        }

        @java.lang.Override
        public _FinalStage addAllMessages(List<ChatMessageV2> messages) {
            this.messages.addAll(messages);
            return this;
        }

        @java.lang.Override
        public _FinalStage addMessages(ChatMessageV2 messages) {
            this.messages.add(messages);
            return this;
        }

        @java.lang.Override
        @JsonSetter(value = "messages", nulls = Nulls.SKIP)
        public _FinalStage messages(List<ChatMessageV2> messages) {
            this.messages.clear();
            this.messages.addAll(messages);
            return this;
        }

        @java.lang.Override
        public V2ChatStreamRequest build() {
            return new V2ChatStreamRequest(
                    model,
                    messages,
                    tools,
                    strictTools,
                    documents,
                    citationOptions,
                    responseFormat,
                    safetyMode,
                    maxTokens,
                    stopSequences,
                    temperature,
                    seed,
                    frequencyPenalty,
                    presencePenalty,
                    k,
                    p,
                    logprobs,
                    toolChoice,
                    thinking,
                    additionalProperties);
        }
    }
}
