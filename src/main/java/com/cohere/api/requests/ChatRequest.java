/**
 * This file was auto-generated by Fern from our API Definition.
 */
package com.cohere.api.requests;

import com.cohere.api.core.ObjectMappers;
import com.cohere.api.types.ChatConnector;
import com.cohere.api.types.ChatRequestCitationQuality;
import com.cohere.api.types.ChatRequestPromptTruncation;
import com.cohere.api.types.ChatRequestSafetyMode;
import com.cohere.api.types.Message;
import com.cohere.api.types.ResponseFormat;
import com.cohere.api.types.Tool;
import com.cohere.api.types.ToolResult;
import com.fasterxml.jackson.annotation.JsonAnyGetter;
import com.fasterxml.jackson.annotation.JsonAnySetter;
import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonSetter;
import com.fasterxml.jackson.annotation.Nulls;
import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import org.jetbrains.annotations.NotNull;

@JsonInclude(JsonInclude.Include.NON_ABSENT)
@JsonDeserialize(builder = ChatRequest.Builder.class)
public final class ChatRequest {
    private final Optional<String> accepts;

    private final Optional<Boolean> rawPrompting;

    private final String message;

    private final Optional<String> model;

    private final Optional<String> preamble;

    private final Optional<List<Message>> chatHistory;

    private final Optional<String> conversationId;

    private final Optional<ChatRequestPromptTruncation> promptTruncation;

    private final Optional<List<ChatConnector>> connectors;

    private final Optional<Boolean> searchQueriesOnly;

    private final Optional<List<Map<String, String>>> documents;

    private final Optional<ChatRequestCitationQuality> citationQuality;

    private final Optional<Float> temperature;

    private final Optional<Integer> maxTokens;

    private final Optional<Integer> maxInputTokens;

    private final Optional<Integer> k;

    private final Optional<Double> p;

    private final Optional<Integer> seed;

    private final Optional<List<String>> stopSequences;

    private final Optional<Double> frequencyPenalty;

    private final Optional<Double> presencePenalty;

    private final Optional<List<Tool>> tools;

    private final Optional<List<ToolResult>> toolResults;

    private final Optional<Boolean> forceSingleStep;

    private final Optional<ResponseFormat> responseFormat;

    private final Optional<ChatRequestSafetyMode> safetyMode;

    private final Map<String, Object> additionalProperties;

    private ChatRequest(
            Optional<String> accepts,
            Optional<Boolean> rawPrompting,
            String message,
            Optional<String> model,
            Optional<String> preamble,
            Optional<List<Message>> chatHistory,
            Optional<String> conversationId,
            Optional<ChatRequestPromptTruncation> promptTruncation,
            Optional<List<ChatConnector>> connectors,
            Optional<Boolean> searchQueriesOnly,
            Optional<List<Map<String, String>>> documents,
            Optional<ChatRequestCitationQuality> citationQuality,
            Optional<Float> temperature,
            Optional<Integer> maxTokens,
            Optional<Integer> maxInputTokens,
            Optional<Integer> k,
            Optional<Double> p,
            Optional<Integer> seed,
            Optional<List<String>> stopSequences,
            Optional<Double> frequencyPenalty,
            Optional<Double> presencePenalty,
            Optional<List<Tool>> tools,
            Optional<List<ToolResult>> toolResults,
            Optional<Boolean> forceSingleStep,
            Optional<ResponseFormat> responseFormat,
            Optional<ChatRequestSafetyMode> safetyMode,
            Map<String, Object> additionalProperties) {
        this.accepts = accepts;
        this.rawPrompting = rawPrompting;
        this.message = message;
        this.model = model;
        this.preamble = preamble;
        this.chatHistory = chatHistory;
        this.conversationId = conversationId;
        this.promptTruncation = promptTruncation;
        this.connectors = connectors;
        this.searchQueriesOnly = searchQueriesOnly;
        this.documents = documents;
        this.citationQuality = citationQuality;
        this.temperature = temperature;
        this.maxTokens = maxTokens;
        this.maxInputTokens = maxInputTokens;
        this.k = k;
        this.p = p;
        this.seed = seed;
        this.stopSequences = stopSequences;
        this.frequencyPenalty = frequencyPenalty;
        this.presencePenalty = presencePenalty;
        this.tools = tools;
        this.toolResults = toolResults;
        this.forceSingleStep = forceSingleStep;
        this.responseFormat = responseFormat;
        this.safetyMode = safetyMode;
        this.additionalProperties = additionalProperties;
    }

    /**
     * @return Pass text/event-stream to receive the streamed response as server-sent events. The default is <code>\n</code> delimited events.
     */
    @JsonProperty("Accepts")
    public Optional<String> getAccepts() {
        return accepts;
    }

    /**
     * @return When enabled, the user's prompt will be sent to the model without
     * any pre-processing.
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("raw_prompting")
    public Optional<Boolean> getRawPrompting() {
        return rawPrompting;
    }

    /**
     * @return Text input for the model to respond to.
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("message")
    public String getMessage() {
        return message;
    }

    /**
     * @return The name of a compatible <a href="https://docs.cohere.com/docs/models">Cohere model</a> or the ID of a <a href="https://docs.cohere.com/docs/chat-fine-tuning">fine-tuned</a> model.
     * <p>Compatible Deployments: Cohere Platform, Private Deployments</p>
     */
    @JsonProperty("model")
    public Optional<String> getModel() {
        return model;
    }

    /**
     * @return Defaults to <code>false</code>.
     * <p>When <code>true</code>, the response will be a JSON stream of events. The final event will contain the complete response, and will have an <code>event_type</code> of <code>&quot;stream-end&quot;</code>.</p>
     * <p>Streaming is beneficial for user interfaces that render the contents of the response piece by piece, as it gets generated.</p>
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("stream")
    public Boolean getStream() {
        return false;
    }

    /**
     * @return When specified, the default Cohere preamble will be replaced with the provided one. Preambles are a part of the prompt used to adjust the model's overall behavior and conversation style, and use the <code>SYSTEM</code> role.
     * <p>The <code>SYSTEM</code> role is also used for the contents of the optional <code>chat_history=</code> parameter. When used with the <code>chat_history=</code> parameter it adds content throughout a conversation. Conversely, when used with the <code>preamble=</code> parameter it adds content at the start of the conversation only.</p>
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("preamble")
    public Optional<String> getPreamble() {
        return preamble;
    }

    /**
     * @return A list of previous messages between the user and the model, giving the model conversational context for responding to the user's <code>message</code>.
     * <p>Each item represents a single message in the chat history, excluding the current user turn. It has two properties: <code>role</code> and <code>message</code>. The <code>role</code> identifies the sender (<code>CHATBOT</code>, <code>SYSTEM</code>, or <code>USER</code>), while the <code>message</code> contains the text content.</p>
     * <p>The chat_history parameter should not be used for <code>SYSTEM</code> messages in most cases. Instead, to add a <code>SYSTEM</code> role message at the beginning of a conversation, the <code>preamble</code> parameter should be used.</p>
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("chat_history")
    public Optional<List<Message>> getChatHistory() {
        return chatHistory;
    }

    /**
     * @return An alternative to <code>chat_history</code>.
     * <p>Providing a <code>conversation_id</code> creates or resumes a persisted conversation with the specified ID. The ID can be any non empty string.</p>
     * <p>Compatible Deployments: Cohere Platform</p>
     */
    @JsonProperty("conversation_id")
    public Optional<String> getConversationId() {
        return conversationId;
    }

    /**
     * @return Defaults to <code>AUTO</code> when <code>connectors</code> are specified and <code>OFF</code> in all other cases.
     * <p>Dictates how the prompt will be constructed.</p>
     * <p>With <code>prompt_truncation</code> set to &quot;AUTO&quot;, some elements from <code>chat_history</code> and <code>documents</code> will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be changed and ranked by relevance.</p>
     * <p>With <code>prompt_truncation</code> set to &quot;AUTO_PRESERVE_ORDER&quot;, some elements from <code>chat_history</code> and <code>documents</code> will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be preserved as they are inputted into the API.</p>
     * <p>With <code>prompt_truncation</code> set to &quot;OFF&quot;, no elements will be dropped. If the sum of the inputs exceeds the model's context length limit, a <code>TooManyTokens</code> error will be returned.</p>
     * <p>Compatible Deployments:</p>
     * <ul>
     * <li>AUTO: Cohere Platform Only</li>
     * <li>AUTO_PRESERVE_ORDER: Azure, AWS Sagemaker/Bedrock, Private Deployments</li>
     * </ul>
     */
    @JsonProperty("prompt_truncation")
    public Optional<ChatRequestPromptTruncation> getPromptTruncation() {
        return promptTruncation;
    }

    /**
     * @return Accepts <code>{&quot;id&quot;: &quot;web-search&quot;}</code>, and/or the <code>&quot;id&quot;</code> for a custom <a href="https://docs.cohere.com/docs/connectors">connector</a>, if you've <a href="https://docs.cohere.com/v1/docs/creating-and-deploying-a-connector">created</a> one.
     * <p>When specified, the model's reply will be enriched with information found by querying each of the connectors (RAG).</p>
     * <p>Compatible Deployments: Cohere Platform</p>
     */
    @JsonProperty("connectors")
    public Optional<List<ChatConnector>> getConnectors() {
        return connectors;
    }

    /**
     * @return Defaults to <code>false</code>.
     * <p>When <code>true</code>, the response will only contain a list of generated search queries, but no search will take place, and no reply from the model to the user's <code>message</code> will be generated.</p>
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("search_queries_only")
    public Optional<Boolean> getSearchQueriesOnly() {
        return searchQueriesOnly;
    }

    /**
     * @return A list of relevant documents that the model can cite to generate a more accurate reply. Each document is a string-string dictionary.
     * <p>Example:</p>
     * <pre><code>[
     *   { &quot;title&quot;: &quot;Tall penguins&quot;, &quot;text&quot;: &quot;Emperor penguins are the tallest.&quot; },
     *   { &quot;title&quot;: &quot;Penguin habitats&quot;, &quot;text&quot;: &quot;Emperor penguins only live in Antarctica.&quot; },
     * ]
     * </code></pre>
     * <p>Keys and values from each document will be serialized to a string and passed to the model. The resulting generation will include citations that reference some of these documents.</p>
     * <p>Some suggested keys are &quot;text&quot;, &quot;author&quot;, and &quot;date&quot;. For better generation quality, it is recommended to keep the total word count of the strings in the dictionary to under 300 words.</p>
     * <p>An <code>id</code> field (string) can be optionally supplied to identify the document in the citations. This field will not be passed to the model.</p>
     * <p>An <code>_excludes</code> field (array of strings) can be optionally supplied to omit some key-value pairs from being shown to the model. The omitted fields will still show up in the citation object. The &quot;_excludes&quot; field will not be passed to the model.</p>
     * <p>See <a href="https://docs.cohere.com/docs/retrieval-augmented-generation-rag#document-mode">'Document Mode'</a> in the guide for more information.</p>
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("documents")
    public Optional<List<Map<String, String>>> getDocuments() {
        return documents;
    }

    /**
     * @return Defaults to <code>&quot;accurate&quot;</code>.
     * <p>Dictates the approach taken to generating citations as part of the RAG flow by allowing the user to specify whether they want <code>&quot;accurate&quot;</code> results, <code>&quot;fast&quot;</code> results or no results.</p>
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("citation_quality")
    public Optional<ChatRequestCitationQuality> getCitationQuality() {
        return citationQuality;
    }

    /**
     * @return Defaults to <code>0.3</code>.
     * <p>A non-negative float that tunes the degree of randomness in generation. Lower temperatures mean less random generations, and higher temperatures mean more random generations.</p>
     * <p>Randomness can be further maximized by increasing the  value of the <code>p</code> parameter.</p>
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("temperature")
    public Optional<Float> getTemperature() {
        return temperature;
    }

    /**
     * @return The maximum number of tokens the model will generate as part of the response. Note: Setting a low value may result in incomplete generations.
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("max_tokens")
    public Optional<Integer> getMaxTokens() {
        return maxTokens;
    }

    /**
     * @return The maximum number of input tokens to send to the model. If not specified, <code>max_input_tokens</code> is the model's context length limit minus a small buffer.
     * <p>Input will be truncated according to the <code>prompt_truncation</code> parameter.</p>
     * <p>Compatible Deployments: Cohere Platform</p>
     */
    @JsonProperty("max_input_tokens")
    public Optional<Integer> getMaxInputTokens() {
        return maxInputTokens;
    }

    /**
     * @return Ensures only the top <code>k</code> most likely tokens are considered for generation at each step.
     * Defaults to <code>0</code>, min value of <code>0</code>, max value of <code>500</code>.
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("k")
    public Optional<Integer> getK() {
        return k;
    }

    /**
     * @return Ensures that only the most likely tokens, with total probability mass of <code>p</code>, are considered for generation at each step. If both <code>k</code> and <code>p</code> are enabled, <code>p</code> acts after <code>k</code>.
     * Defaults to <code>0.75</code>. min value of <code>0.01</code>, max value of <code>0.99</code>.
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("p")
    public Optional<Double> getP() {
        return p;
    }

    /**
     * @return If specified, the backend will make a best effort to sample tokens
     * deterministically, such that repeated requests with the same
     * seed and parameters should return the same result. However,
     * determinism cannot be totally guaranteed.
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("seed")
    public Optional<Integer> getSeed() {
        return seed;
    }

    /**
     * @return A list of up to 5 strings that the model will use to stop generation. If the model generates a string that matches any of the strings in the list, it will stop generating tokens and return the generated text up to that point not including the stop sequence.
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("stop_sequences")
    public Optional<List<String>> getStopSequences() {
        return stopSequences;
    }

    /**
     * @return Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.
     * <p>Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.</p>
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("frequency_penalty")
    public Optional<Double> getFrequencyPenalty() {
        return frequencyPenalty;
    }

    /**
     * @return Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.
     * <p>Used to reduce repetitiveness of generated tokens. Similar to <code>frequency_penalty</code>, except that this penalty is applied equally to all tokens that have already appeared, regardless of their exact frequencies.</p>
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("presence_penalty")
    public Optional<Double> getPresencePenalty() {
        return presencePenalty;
    }

    /**
     * @return A list of available tools (functions) that the model may suggest invoking before producing a text response.
     * <p>When <code>tools</code> is passed (without <code>tool_results</code>), the <code>text</code> field in the response will be <code>&quot;&quot;</code> and the <code>tool_calls</code> field in the response will be populated with a list of tool calls that need to be made. If no calls need to be made, the <code>tool_calls</code> array will be empty.</p>
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("tools")
    public Optional<List<Tool>> getTools() {
        return tools;
    }

    /**
     * @return A list of results from invoking tools recommended by the model in the previous chat turn. Results are used to produce a text response and will be referenced in citations. When using <code>tool_results</code>, <code>tools</code> must be passed as well.
     * Each tool_result contains information about how it was invoked, as well as a list of outputs in the form of dictionaries.
     * <p><strong>Note</strong>: <code>outputs</code> must be a list of objects. If your tool returns a single object (eg <code>{&quot;status&quot;: 200}</code>), make sure to wrap it in a list.</p>
     * <pre><code>tool_results = [
     *   {
     *     &quot;call&quot;: {
     *       &quot;name&quot;: &lt;tool name&gt;,
     *       &quot;parameters&quot;: {
     *         &lt;param name&gt;: &lt;param value&gt;
     *       }
     *     },
     *     &quot;outputs&quot;: [{
     *       &lt;key&gt;: &lt;value&gt;
     *     }]
     *   },
     *   ...
     * ]
     * </code></pre>
     * <p><strong>Note</strong>: Chat calls with <code>tool_results</code> should not be included in the Chat history to avoid duplication of the message text.</p>
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("tool_results")
    public Optional<List<ToolResult>> getToolResults() {
        return toolResults;
    }

    /**
     * @return Forces the chat to be single step. Defaults to <code>false</code>.
     */
    @JsonProperty("force_single_step")
    public Optional<Boolean> getForceSingleStep() {
        return forceSingleStep;
    }

    @JsonProperty("response_format")
    public Optional<ResponseFormat> getResponseFormat() {
        return responseFormat;
    }

    /**
     * @return Used to select the <a href="https://docs.cohere.com/docs/safety-modes">safety instruction</a> inserted into the prompt. Defaults to <code>CONTEXTUAL</code>.
     * When <code>NONE</code> is specified, the safety instruction will be omitted.
     * <p>Safety modes are not yet configurable in combination with <code>tools</code>, <code>tool_results</code> and <code>documents</code> parameters.</p>
     * <p><strong>Note</strong>: This parameter is only compatible newer Cohere models, starting with <a href="https://docs.cohere.com/docs/command-r#august-2024-release">Command R 08-2024</a> and <a href="https://docs.cohere.com/docs/command-r-plus#august-2024-release">Command R+ 08-2024</a>.</p>
     * <p><strong>Note</strong>: <code>command-r7b-12-2024</code> and newer models only support <code>&quot;CONTEXTUAL&quot;</code> and <code>&quot;STRICT&quot;</code> modes.</p>
     * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
     */
    @JsonProperty("safety_mode")
    public Optional<ChatRequestSafetyMode> getSafetyMode() {
        return safetyMode;
    }

    @java.lang.Override
    public boolean equals(Object other) {
        if (this == other) return true;
        return other instanceof ChatRequest && equalTo((ChatRequest) other);
    }

    @JsonAnyGetter
    public Map<String, Object> getAdditionalProperties() {
        return this.additionalProperties;
    }

    private boolean equalTo(ChatRequest other) {
        return accepts.equals(other.accepts)
                && rawPrompting.equals(other.rawPrompting)
                && message.equals(other.message)
                && model.equals(other.model)
                && preamble.equals(other.preamble)
                && chatHistory.equals(other.chatHistory)
                && conversationId.equals(other.conversationId)
                && promptTruncation.equals(other.promptTruncation)
                && connectors.equals(other.connectors)
                && searchQueriesOnly.equals(other.searchQueriesOnly)
                && documents.equals(other.documents)
                && citationQuality.equals(other.citationQuality)
                && temperature.equals(other.temperature)
                && maxTokens.equals(other.maxTokens)
                && maxInputTokens.equals(other.maxInputTokens)
                && k.equals(other.k)
                && p.equals(other.p)
                && seed.equals(other.seed)
                && stopSequences.equals(other.stopSequences)
                && frequencyPenalty.equals(other.frequencyPenalty)
                && presencePenalty.equals(other.presencePenalty)
                && tools.equals(other.tools)
                && toolResults.equals(other.toolResults)
                && forceSingleStep.equals(other.forceSingleStep)
                && responseFormat.equals(other.responseFormat)
                && safetyMode.equals(other.safetyMode);
    }

    @java.lang.Override
    public int hashCode() {
        return Objects.hash(
                this.accepts,
                this.rawPrompting,
                this.message,
                this.model,
                this.preamble,
                this.chatHistory,
                this.conversationId,
                this.promptTruncation,
                this.connectors,
                this.searchQueriesOnly,
                this.documents,
                this.citationQuality,
                this.temperature,
                this.maxTokens,
                this.maxInputTokens,
                this.k,
                this.p,
                this.seed,
                this.stopSequences,
                this.frequencyPenalty,
                this.presencePenalty,
                this.tools,
                this.toolResults,
                this.forceSingleStep,
                this.responseFormat,
                this.safetyMode);
    }

    @java.lang.Override
    public String toString() {
        return ObjectMappers.stringify(this);
    }

    public static MessageStage builder() {
        return new Builder();
    }

    public interface MessageStage {
        /**
         * <p>Text input for the model to respond to.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage message(@NotNull String message);

        Builder from(ChatRequest other);
    }

    public interface _FinalStage {
        ChatRequest build();

        /**
         * <p>Pass text/event-stream to receive the streamed response as server-sent events. The default is <code>\n</code> delimited events.</p>
         */
        _FinalStage accepts(Optional<String> accepts);

        _FinalStage accepts(String accepts);

        /**
         * <p>When enabled, the user's prompt will be sent to the model without
         * any pre-processing.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage rawPrompting(Optional<Boolean> rawPrompting);

        _FinalStage rawPrompting(Boolean rawPrompting);

        /**
         * <p>The name of a compatible <a href="https://docs.cohere.com/docs/models">Cohere model</a> or the ID of a <a href="https://docs.cohere.com/docs/chat-fine-tuning">fine-tuned</a> model.</p>
         * <p>Compatible Deployments: Cohere Platform, Private Deployments</p>
         */
        _FinalStage model(Optional<String> model);

        _FinalStage model(String model);

        /**
         * <p>When specified, the default Cohere preamble will be replaced with the provided one. Preambles are a part of the prompt used to adjust the model's overall behavior and conversation style, and use the <code>SYSTEM</code> role.</p>
         * <p>The <code>SYSTEM</code> role is also used for the contents of the optional <code>chat_history=</code> parameter. When used with the <code>chat_history=</code> parameter it adds content throughout a conversation. Conversely, when used with the <code>preamble=</code> parameter it adds content at the start of the conversation only.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage preamble(Optional<String> preamble);

        _FinalStage preamble(String preamble);

        /**
         * <p>A list of previous messages between the user and the model, giving the model conversational context for responding to the user's <code>message</code>.</p>
         * <p>Each item represents a single message in the chat history, excluding the current user turn. It has two properties: <code>role</code> and <code>message</code>. The <code>role</code> identifies the sender (<code>CHATBOT</code>, <code>SYSTEM</code>, or <code>USER</code>), while the <code>message</code> contains the text content.</p>
         * <p>The chat_history parameter should not be used for <code>SYSTEM</code> messages in most cases. Instead, to add a <code>SYSTEM</code> role message at the beginning of a conversation, the <code>preamble</code> parameter should be used.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage chatHistory(Optional<List<Message>> chatHistory);

        _FinalStage chatHistory(List<Message> chatHistory);

        /**
         * <p>An alternative to <code>chat_history</code>.</p>
         * <p>Providing a <code>conversation_id</code> creates or resumes a persisted conversation with the specified ID. The ID can be any non empty string.</p>
         * <p>Compatible Deployments: Cohere Platform</p>
         */
        _FinalStage conversationId(Optional<String> conversationId);

        _FinalStage conversationId(String conversationId);

        /**
         * <p>Defaults to <code>AUTO</code> when <code>connectors</code> are specified and <code>OFF</code> in all other cases.</p>
         * <p>Dictates how the prompt will be constructed.</p>
         * <p>With <code>prompt_truncation</code> set to &quot;AUTO&quot;, some elements from <code>chat_history</code> and <code>documents</code> will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be changed and ranked by relevance.</p>
         * <p>With <code>prompt_truncation</code> set to &quot;AUTO_PRESERVE_ORDER&quot;, some elements from <code>chat_history</code> and <code>documents</code> will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be preserved as they are inputted into the API.</p>
         * <p>With <code>prompt_truncation</code> set to &quot;OFF&quot;, no elements will be dropped. If the sum of the inputs exceeds the model's context length limit, a <code>TooManyTokens</code> error will be returned.</p>
         * <p>Compatible Deployments:</p>
         * <ul>
         * <li>AUTO: Cohere Platform Only</li>
         * <li>AUTO_PRESERVE_ORDER: Azure, AWS Sagemaker/Bedrock, Private Deployments</li>
         * </ul>
         */
        _FinalStage promptTruncation(Optional<ChatRequestPromptTruncation> promptTruncation);

        _FinalStage promptTruncation(ChatRequestPromptTruncation promptTruncation);

        /**
         * <p>Accepts <code>{&quot;id&quot;: &quot;web-search&quot;}</code>, and/or the <code>&quot;id&quot;</code> for a custom <a href="https://docs.cohere.com/docs/connectors">connector</a>, if you've <a href="https://docs.cohere.com/v1/docs/creating-and-deploying-a-connector">created</a> one.</p>
         * <p>When specified, the model's reply will be enriched with information found by querying each of the connectors (RAG).</p>
         * <p>Compatible Deployments: Cohere Platform</p>
         */
        _FinalStage connectors(Optional<List<ChatConnector>> connectors);

        _FinalStage connectors(List<ChatConnector> connectors);

        /**
         * <p>Defaults to <code>false</code>.</p>
         * <p>When <code>true</code>, the response will only contain a list of generated search queries, but no search will take place, and no reply from the model to the user's <code>message</code> will be generated.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage searchQueriesOnly(Optional<Boolean> searchQueriesOnly);

        _FinalStage searchQueriesOnly(Boolean searchQueriesOnly);

        /**
         * <p>A list of relevant documents that the model can cite to generate a more accurate reply. Each document is a string-string dictionary.</p>
         * <p>Example:</p>
         * <pre><code>[
         *   { &quot;title&quot;: &quot;Tall penguins&quot;, &quot;text&quot;: &quot;Emperor penguins are the tallest.&quot; },
         *   { &quot;title&quot;: &quot;Penguin habitats&quot;, &quot;text&quot;: &quot;Emperor penguins only live in Antarctica.&quot; },
         * ]
         * </code></pre>
         * <p>Keys and values from each document will be serialized to a string and passed to the model. The resulting generation will include citations that reference some of these documents.</p>
         * <p>Some suggested keys are &quot;text&quot;, &quot;author&quot;, and &quot;date&quot;. For better generation quality, it is recommended to keep the total word count of the strings in the dictionary to under 300 words.</p>
         * <p>An <code>id</code> field (string) can be optionally supplied to identify the document in the citations. This field will not be passed to the model.</p>
         * <p>An <code>_excludes</code> field (array of strings) can be optionally supplied to omit some key-value pairs from being shown to the model. The omitted fields will still show up in the citation object. The &quot;_excludes&quot; field will not be passed to the model.</p>
         * <p>See <a href="https://docs.cohere.com/docs/retrieval-augmented-generation-rag#document-mode">'Document Mode'</a> in the guide for more information.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage documents(Optional<List<Map<String, String>>> documents);

        _FinalStage documents(List<Map<String, String>> documents);

        /**
         * <p>Defaults to <code>&quot;accurate&quot;</code>.</p>
         * <p>Dictates the approach taken to generating citations as part of the RAG flow by allowing the user to specify whether they want <code>&quot;accurate&quot;</code> results, <code>&quot;fast&quot;</code> results or no results.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage citationQuality(Optional<ChatRequestCitationQuality> citationQuality);

        _FinalStage citationQuality(ChatRequestCitationQuality citationQuality);

        /**
         * <p>Defaults to <code>0.3</code>.</p>
         * <p>A non-negative float that tunes the degree of randomness in generation. Lower temperatures mean less random generations, and higher temperatures mean more random generations.</p>
         * <p>Randomness can be further maximized by increasing the  value of the <code>p</code> parameter.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage temperature(Optional<Float> temperature);

        _FinalStage temperature(Float temperature);

        /**
         * <p>The maximum number of tokens the model will generate as part of the response. Note: Setting a low value may result in incomplete generations.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage maxTokens(Optional<Integer> maxTokens);

        _FinalStage maxTokens(Integer maxTokens);

        /**
         * <p>The maximum number of input tokens to send to the model. If not specified, <code>max_input_tokens</code> is the model's context length limit minus a small buffer.</p>
         * <p>Input will be truncated according to the <code>prompt_truncation</code> parameter.</p>
         * <p>Compatible Deployments: Cohere Platform</p>
         */
        _FinalStage maxInputTokens(Optional<Integer> maxInputTokens);

        _FinalStage maxInputTokens(Integer maxInputTokens);

        /**
         * <p>Ensures only the top <code>k</code> most likely tokens are considered for generation at each step.
         * Defaults to <code>0</code>, min value of <code>0</code>, max value of <code>500</code>.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage k(Optional<Integer> k);

        _FinalStage k(Integer k);

        /**
         * <p>Ensures that only the most likely tokens, with total probability mass of <code>p</code>, are considered for generation at each step. If both <code>k</code> and <code>p</code> are enabled, <code>p</code> acts after <code>k</code>.
         * Defaults to <code>0.75</code>. min value of <code>0.01</code>, max value of <code>0.99</code>.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage p(Optional<Double> p);

        _FinalStage p(Double p);

        /**
         * <p>If specified, the backend will make a best effort to sample tokens
         * deterministically, such that repeated requests with the same
         * seed and parameters should return the same result. However,
         * determinism cannot be totally guaranteed.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage seed(Optional<Integer> seed);

        _FinalStage seed(Integer seed);

        /**
         * <p>A list of up to 5 strings that the model will use to stop generation. If the model generates a string that matches any of the strings in the list, it will stop generating tokens and return the generated text up to that point not including the stop sequence.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage stopSequences(Optional<List<String>> stopSequences);

        _FinalStage stopSequences(List<String> stopSequences);

        /**
         * <p>Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.</p>
         * <p>Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage frequencyPenalty(Optional<Double> frequencyPenalty);

        _FinalStage frequencyPenalty(Double frequencyPenalty);

        /**
         * <p>Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.</p>
         * <p>Used to reduce repetitiveness of generated tokens. Similar to <code>frequency_penalty</code>, except that this penalty is applied equally to all tokens that have already appeared, regardless of their exact frequencies.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage presencePenalty(Optional<Double> presencePenalty);

        _FinalStage presencePenalty(Double presencePenalty);

        /**
         * <p>A list of available tools (functions) that the model may suggest invoking before producing a text response.</p>
         * <p>When <code>tools</code> is passed (without <code>tool_results</code>), the <code>text</code> field in the response will be <code>&quot;&quot;</code> and the <code>tool_calls</code> field in the response will be populated with a list of tool calls that need to be made. If no calls need to be made, the <code>tool_calls</code> array will be empty.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage tools(Optional<List<Tool>> tools);

        _FinalStage tools(List<Tool> tools);

        /**
         * <p>A list of results from invoking tools recommended by the model in the previous chat turn. Results are used to produce a text response and will be referenced in citations. When using <code>tool_results</code>, <code>tools</code> must be passed as well.
         * Each tool_result contains information about how it was invoked, as well as a list of outputs in the form of dictionaries.</p>
         * <p><strong>Note</strong>: <code>outputs</code> must be a list of objects. If your tool returns a single object (eg <code>{&quot;status&quot;: 200}</code>), make sure to wrap it in a list.</p>
         * <pre><code>tool_results = [
         *   {
         *     &quot;call&quot;: {
         *       &quot;name&quot;: &lt;tool name&gt;,
         *       &quot;parameters&quot;: {
         *         &lt;param name&gt;: &lt;param value&gt;
         *       }
         *     },
         *     &quot;outputs&quot;: [{
         *       &lt;key&gt;: &lt;value&gt;
         *     }]
         *   },
         *   ...
         * ]
         * </code></pre>
         * <p><strong>Note</strong>: Chat calls with <code>tool_results</code> should not be included in the Chat history to avoid duplication of the message text.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage toolResults(Optional<List<ToolResult>> toolResults);

        _FinalStage toolResults(List<ToolResult> toolResults);

        /**
         * <p>Forces the chat to be single step. Defaults to <code>false</code>.</p>
         */
        _FinalStage forceSingleStep(Optional<Boolean> forceSingleStep);

        _FinalStage forceSingleStep(Boolean forceSingleStep);

        _FinalStage responseFormat(Optional<ResponseFormat> responseFormat);

        _FinalStage responseFormat(ResponseFormat responseFormat);

        /**
         * <p>Used to select the <a href="https://docs.cohere.com/docs/safety-modes">safety instruction</a> inserted into the prompt. Defaults to <code>CONTEXTUAL</code>.
         * When <code>NONE</code> is specified, the safety instruction will be omitted.</p>
         * <p>Safety modes are not yet configurable in combination with <code>tools</code>, <code>tool_results</code> and <code>documents</code> parameters.</p>
         * <p><strong>Note</strong>: This parameter is only compatible newer Cohere models, starting with <a href="https://docs.cohere.com/docs/command-r#august-2024-release">Command R 08-2024</a> and <a href="https://docs.cohere.com/docs/command-r-plus#august-2024-release">Command R+ 08-2024</a>.</p>
         * <p><strong>Note</strong>: <code>command-r7b-12-2024</code> and newer models only support <code>&quot;CONTEXTUAL&quot;</code> and <code>&quot;STRICT&quot;</code> modes.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        _FinalStage safetyMode(Optional<ChatRequestSafetyMode> safetyMode);

        _FinalStage safetyMode(ChatRequestSafetyMode safetyMode);
    }

    @JsonIgnoreProperties(ignoreUnknown = true)
    public static final class Builder implements MessageStage, _FinalStage {
        private String message;

        private Optional<ChatRequestSafetyMode> safetyMode = Optional.empty();

        private Optional<ResponseFormat> responseFormat = Optional.empty();

        private Optional<Boolean> forceSingleStep = Optional.empty();

        private Optional<List<ToolResult>> toolResults = Optional.empty();

        private Optional<List<Tool>> tools = Optional.empty();

        private Optional<Double> presencePenalty = Optional.empty();

        private Optional<Double> frequencyPenalty = Optional.empty();

        private Optional<List<String>> stopSequences = Optional.empty();

        private Optional<Integer> seed = Optional.empty();

        private Optional<Double> p = Optional.empty();

        private Optional<Integer> k = Optional.empty();

        private Optional<Integer> maxInputTokens = Optional.empty();

        private Optional<Integer> maxTokens = Optional.empty();

        private Optional<Float> temperature = Optional.empty();

        private Optional<ChatRequestCitationQuality> citationQuality = Optional.empty();

        private Optional<List<Map<String, String>>> documents = Optional.empty();

        private Optional<Boolean> searchQueriesOnly = Optional.empty();

        private Optional<List<ChatConnector>> connectors = Optional.empty();

        private Optional<ChatRequestPromptTruncation> promptTruncation = Optional.empty();

        private Optional<String> conversationId = Optional.empty();

        private Optional<List<Message>> chatHistory = Optional.empty();

        private Optional<String> preamble = Optional.empty();

        private Optional<String> model = Optional.empty();

        private Optional<Boolean> rawPrompting = Optional.empty();

        private Optional<String> accepts = Optional.empty();

        @JsonAnySetter
        private Map<String, Object> additionalProperties = new HashMap<>();

        private Builder() {}

        @java.lang.Override
        public Builder from(ChatRequest other) {
            accepts(other.getAccepts());
            rawPrompting(other.getRawPrompting());
            message(other.getMessage());
            model(other.getModel());
            preamble(other.getPreamble());
            chatHistory(other.getChatHistory());
            conversationId(other.getConversationId());
            promptTruncation(other.getPromptTruncation());
            connectors(other.getConnectors());
            searchQueriesOnly(other.getSearchQueriesOnly());
            documents(other.getDocuments());
            citationQuality(other.getCitationQuality());
            temperature(other.getTemperature());
            maxTokens(other.getMaxTokens());
            maxInputTokens(other.getMaxInputTokens());
            k(other.getK());
            p(other.getP());
            seed(other.getSeed());
            stopSequences(other.getStopSequences());
            frequencyPenalty(other.getFrequencyPenalty());
            presencePenalty(other.getPresencePenalty());
            tools(other.getTools());
            toolResults(other.getToolResults());
            forceSingleStep(other.getForceSingleStep());
            responseFormat(other.getResponseFormat());
            safetyMode(other.getSafetyMode());
            return this;
        }

        /**
         * <p>Text input for the model to respond to.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * <p>Text input for the model to respond to.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        @JsonSetter("message")
        public _FinalStage message(@NotNull String message) {
            this.message = Objects.requireNonNull(message, "message must not be null");
            return this;
        }

        /**
         * <p>Used to select the <a href="https://docs.cohere.com/docs/safety-modes">safety instruction</a> inserted into the prompt. Defaults to <code>CONTEXTUAL</code>.
         * When <code>NONE</code> is specified, the safety instruction will be omitted.</p>
         * <p>Safety modes are not yet configurable in combination with <code>tools</code>, <code>tool_results</code> and <code>documents</code> parameters.</p>
         * <p><strong>Note</strong>: This parameter is only compatible newer Cohere models, starting with <a href="https://docs.cohere.com/docs/command-r#august-2024-release">Command R 08-2024</a> and <a href="https://docs.cohere.com/docs/command-r-plus#august-2024-release">Command R+ 08-2024</a>.</p>
         * <p><strong>Note</strong>: <code>command-r7b-12-2024</code> and newer models only support <code>&quot;CONTEXTUAL&quot;</code> and <code>&quot;STRICT&quot;</code> modes.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage safetyMode(ChatRequestSafetyMode safetyMode) {
            this.safetyMode = Optional.ofNullable(safetyMode);
            return this;
        }

        /**
         * <p>Used to select the <a href="https://docs.cohere.com/docs/safety-modes">safety instruction</a> inserted into the prompt. Defaults to <code>CONTEXTUAL</code>.
         * When <code>NONE</code> is specified, the safety instruction will be omitted.</p>
         * <p>Safety modes are not yet configurable in combination with <code>tools</code>, <code>tool_results</code> and <code>documents</code> parameters.</p>
         * <p><strong>Note</strong>: This parameter is only compatible newer Cohere models, starting with <a href="https://docs.cohere.com/docs/command-r#august-2024-release">Command R 08-2024</a> and <a href="https://docs.cohere.com/docs/command-r-plus#august-2024-release">Command R+ 08-2024</a>.</p>
         * <p><strong>Note</strong>: <code>command-r7b-12-2024</code> and newer models only support <code>&quot;CONTEXTUAL&quot;</code> and <code>&quot;STRICT&quot;</code> modes.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "safety_mode", nulls = Nulls.SKIP)
        public _FinalStage safetyMode(Optional<ChatRequestSafetyMode> safetyMode) {
            this.safetyMode = safetyMode;
            return this;
        }

        @java.lang.Override
        public _FinalStage responseFormat(ResponseFormat responseFormat) {
            this.responseFormat = Optional.ofNullable(responseFormat);
            return this;
        }

        @java.lang.Override
        @JsonSetter(value = "response_format", nulls = Nulls.SKIP)
        public _FinalStage responseFormat(Optional<ResponseFormat> responseFormat) {
            this.responseFormat = responseFormat;
            return this;
        }

        /**
         * <p>Forces the chat to be single step. Defaults to <code>false</code>.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage forceSingleStep(Boolean forceSingleStep) {
            this.forceSingleStep = Optional.ofNullable(forceSingleStep);
            return this;
        }

        /**
         * <p>Forces the chat to be single step. Defaults to <code>false</code>.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "force_single_step", nulls = Nulls.SKIP)
        public _FinalStage forceSingleStep(Optional<Boolean> forceSingleStep) {
            this.forceSingleStep = forceSingleStep;
            return this;
        }

        /**
         * <p>A list of results from invoking tools recommended by the model in the previous chat turn. Results are used to produce a text response and will be referenced in citations. When using <code>tool_results</code>, <code>tools</code> must be passed as well.
         * Each tool_result contains information about how it was invoked, as well as a list of outputs in the form of dictionaries.</p>
         * <p><strong>Note</strong>: <code>outputs</code> must be a list of objects. If your tool returns a single object (eg <code>{&quot;status&quot;: 200}</code>), make sure to wrap it in a list.</p>
         * <pre><code>tool_results = [
         *   {
         *     &quot;call&quot;: {
         *       &quot;name&quot;: &lt;tool name&gt;,
         *       &quot;parameters&quot;: {
         *         &lt;param name&gt;: &lt;param value&gt;
         *       }
         *     },
         *     &quot;outputs&quot;: [{
         *       &lt;key&gt;: &lt;value&gt;
         *     }]
         *   },
         *   ...
         * ]
         * </code></pre>
         * <p><strong>Note</strong>: Chat calls with <code>tool_results</code> should not be included in the Chat history to avoid duplication of the message text.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage toolResults(List<ToolResult> toolResults) {
            this.toolResults = Optional.ofNullable(toolResults);
            return this;
        }

        /**
         * <p>A list of results from invoking tools recommended by the model in the previous chat turn. Results are used to produce a text response and will be referenced in citations. When using <code>tool_results</code>, <code>tools</code> must be passed as well.
         * Each tool_result contains information about how it was invoked, as well as a list of outputs in the form of dictionaries.</p>
         * <p><strong>Note</strong>: <code>outputs</code> must be a list of objects. If your tool returns a single object (eg <code>{&quot;status&quot;: 200}</code>), make sure to wrap it in a list.</p>
         * <pre><code>tool_results = [
         *   {
         *     &quot;call&quot;: {
         *       &quot;name&quot;: &lt;tool name&gt;,
         *       &quot;parameters&quot;: {
         *         &lt;param name&gt;: &lt;param value&gt;
         *       }
         *     },
         *     &quot;outputs&quot;: [{
         *       &lt;key&gt;: &lt;value&gt;
         *     }]
         *   },
         *   ...
         * ]
         * </code></pre>
         * <p><strong>Note</strong>: Chat calls with <code>tool_results</code> should not be included in the Chat history to avoid duplication of the message text.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "tool_results", nulls = Nulls.SKIP)
        public _FinalStage toolResults(Optional<List<ToolResult>> toolResults) {
            this.toolResults = toolResults;
            return this;
        }

        /**
         * <p>A list of available tools (functions) that the model may suggest invoking before producing a text response.</p>
         * <p>When <code>tools</code> is passed (without <code>tool_results</code>), the <code>text</code> field in the response will be <code>&quot;&quot;</code> and the <code>tool_calls</code> field in the response will be populated with a list of tool calls that need to be made. If no calls need to be made, the <code>tool_calls</code> array will be empty.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage tools(List<Tool> tools) {
            this.tools = Optional.ofNullable(tools);
            return this;
        }

        /**
         * <p>A list of available tools (functions) that the model may suggest invoking before producing a text response.</p>
         * <p>When <code>tools</code> is passed (without <code>tool_results</code>), the <code>text</code> field in the response will be <code>&quot;&quot;</code> and the <code>tool_calls</code> field in the response will be populated with a list of tool calls that need to be made. If no calls need to be made, the <code>tool_calls</code> array will be empty.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "tools", nulls = Nulls.SKIP)
        public _FinalStage tools(Optional<List<Tool>> tools) {
            this.tools = tools;
            return this;
        }

        /**
         * <p>Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.</p>
         * <p>Used to reduce repetitiveness of generated tokens. Similar to <code>frequency_penalty</code>, except that this penalty is applied equally to all tokens that have already appeared, regardless of their exact frequencies.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage presencePenalty(Double presencePenalty) {
            this.presencePenalty = Optional.ofNullable(presencePenalty);
            return this;
        }

        /**
         * <p>Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.</p>
         * <p>Used to reduce repetitiveness of generated tokens. Similar to <code>frequency_penalty</code>, except that this penalty is applied equally to all tokens that have already appeared, regardless of their exact frequencies.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "presence_penalty", nulls = Nulls.SKIP)
        public _FinalStage presencePenalty(Optional<Double> presencePenalty) {
            this.presencePenalty = presencePenalty;
            return this;
        }

        /**
         * <p>Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.</p>
         * <p>Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage frequencyPenalty(Double frequencyPenalty) {
            this.frequencyPenalty = Optional.ofNullable(frequencyPenalty);
            return this;
        }

        /**
         * <p>Defaults to <code>0.0</code>, min value of <code>0.0</code>, max value of <code>1.0</code>.</p>
         * <p>Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to previously present tokens, proportional to how many times they have already appeared in the prompt or prior generation.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "frequency_penalty", nulls = Nulls.SKIP)
        public _FinalStage frequencyPenalty(Optional<Double> frequencyPenalty) {
            this.frequencyPenalty = frequencyPenalty;
            return this;
        }

        /**
         * <p>A list of up to 5 strings that the model will use to stop generation. If the model generates a string that matches any of the strings in the list, it will stop generating tokens and return the generated text up to that point not including the stop sequence.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage stopSequences(List<String> stopSequences) {
            this.stopSequences = Optional.ofNullable(stopSequences);
            return this;
        }

        /**
         * <p>A list of up to 5 strings that the model will use to stop generation. If the model generates a string that matches any of the strings in the list, it will stop generating tokens and return the generated text up to that point not including the stop sequence.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "stop_sequences", nulls = Nulls.SKIP)
        public _FinalStage stopSequences(Optional<List<String>> stopSequences) {
            this.stopSequences = stopSequences;
            return this;
        }

        /**
         * <p>If specified, the backend will make a best effort to sample tokens
         * deterministically, such that repeated requests with the same
         * seed and parameters should return the same result. However,
         * determinism cannot be totally guaranteed.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage seed(Integer seed) {
            this.seed = Optional.ofNullable(seed);
            return this;
        }

        /**
         * <p>If specified, the backend will make a best effort to sample tokens
         * deterministically, such that repeated requests with the same
         * seed and parameters should return the same result. However,
         * determinism cannot be totally guaranteed.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "seed", nulls = Nulls.SKIP)
        public _FinalStage seed(Optional<Integer> seed) {
            this.seed = seed;
            return this;
        }

        /**
         * <p>Ensures that only the most likely tokens, with total probability mass of <code>p</code>, are considered for generation at each step. If both <code>k</code> and <code>p</code> are enabled, <code>p</code> acts after <code>k</code>.
         * Defaults to <code>0.75</code>. min value of <code>0.01</code>, max value of <code>0.99</code>.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage p(Double p) {
            this.p = Optional.ofNullable(p);
            return this;
        }

        /**
         * <p>Ensures that only the most likely tokens, with total probability mass of <code>p</code>, are considered for generation at each step. If both <code>k</code> and <code>p</code> are enabled, <code>p</code> acts after <code>k</code>.
         * Defaults to <code>0.75</code>. min value of <code>0.01</code>, max value of <code>0.99</code>.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "p", nulls = Nulls.SKIP)
        public _FinalStage p(Optional<Double> p) {
            this.p = p;
            return this;
        }

        /**
         * <p>Ensures only the top <code>k</code> most likely tokens are considered for generation at each step.
         * Defaults to <code>0</code>, min value of <code>0</code>, max value of <code>500</code>.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage k(Integer k) {
            this.k = Optional.ofNullable(k);
            return this;
        }

        /**
         * <p>Ensures only the top <code>k</code> most likely tokens are considered for generation at each step.
         * Defaults to <code>0</code>, min value of <code>0</code>, max value of <code>500</code>.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "k", nulls = Nulls.SKIP)
        public _FinalStage k(Optional<Integer> k) {
            this.k = k;
            return this;
        }

        /**
         * <p>The maximum number of input tokens to send to the model. If not specified, <code>max_input_tokens</code> is the model's context length limit minus a small buffer.</p>
         * <p>Input will be truncated according to the <code>prompt_truncation</code> parameter.</p>
         * <p>Compatible Deployments: Cohere Platform</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage maxInputTokens(Integer maxInputTokens) {
            this.maxInputTokens = Optional.ofNullable(maxInputTokens);
            return this;
        }

        /**
         * <p>The maximum number of input tokens to send to the model. If not specified, <code>max_input_tokens</code> is the model's context length limit minus a small buffer.</p>
         * <p>Input will be truncated according to the <code>prompt_truncation</code> parameter.</p>
         * <p>Compatible Deployments: Cohere Platform</p>
         */
        @java.lang.Override
        @JsonSetter(value = "max_input_tokens", nulls = Nulls.SKIP)
        public _FinalStage maxInputTokens(Optional<Integer> maxInputTokens) {
            this.maxInputTokens = maxInputTokens;
            return this;
        }

        /**
         * <p>The maximum number of tokens the model will generate as part of the response. Note: Setting a low value may result in incomplete generations.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage maxTokens(Integer maxTokens) {
            this.maxTokens = Optional.ofNullable(maxTokens);
            return this;
        }

        /**
         * <p>The maximum number of tokens the model will generate as part of the response. Note: Setting a low value may result in incomplete generations.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "max_tokens", nulls = Nulls.SKIP)
        public _FinalStage maxTokens(Optional<Integer> maxTokens) {
            this.maxTokens = maxTokens;
            return this;
        }

        /**
         * <p>Defaults to <code>0.3</code>.</p>
         * <p>A non-negative float that tunes the degree of randomness in generation. Lower temperatures mean less random generations, and higher temperatures mean more random generations.</p>
         * <p>Randomness can be further maximized by increasing the  value of the <code>p</code> parameter.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage temperature(Float temperature) {
            this.temperature = Optional.ofNullable(temperature);
            return this;
        }

        /**
         * <p>Defaults to <code>0.3</code>.</p>
         * <p>A non-negative float that tunes the degree of randomness in generation. Lower temperatures mean less random generations, and higher temperatures mean more random generations.</p>
         * <p>Randomness can be further maximized by increasing the  value of the <code>p</code> parameter.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "temperature", nulls = Nulls.SKIP)
        public _FinalStage temperature(Optional<Float> temperature) {
            this.temperature = temperature;
            return this;
        }

        /**
         * <p>Defaults to <code>&quot;accurate&quot;</code>.</p>
         * <p>Dictates the approach taken to generating citations as part of the RAG flow by allowing the user to specify whether they want <code>&quot;accurate&quot;</code> results, <code>&quot;fast&quot;</code> results or no results.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage citationQuality(ChatRequestCitationQuality citationQuality) {
            this.citationQuality = Optional.ofNullable(citationQuality);
            return this;
        }

        /**
         * <p>Defaults to <code>&quot;accurate&quot;</code>.</p>
         * <p>Dictates the approach taken to generating citations as part of the RAG flow by allowing the user to specify whether they want <code>&quot;accurate&quot;</code> results, <code>&quot;fast&quot;</code> results or no results.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "citation_quality", nulls = Nulls.SKIP)
        public _FinalStage citationQuality(Optional<ChatRequestCitationQuality> citationQuality) {
            this.citationQuality = citationQuality;
            return this;
        }

        /**
         * <p>A list of relevant documents that the model can cite to generate a more accurate reply. Each document is a string-string dictionary.</p>
         * <p>Example:</p>
         * <pre><code>[
         *   { &quot;title&quot;: &quot;Tall penguins&quot;, &quot;text&quot;: &quot;Emperor penguins are the tallest.&quot; },
         *   { &quot;title&quot;: &quot;Penguin habitats&quot;, &quot;text&quot;: &quot;Emperor penguins only live in Antarctica.&quot; },
         * ]
         * </code></pre>
         * <p>Keys and values from each document will be serialized to a string and passed to the model. The resulting generation will include citations that reference some of these documents.</p>
         * <p>Some suggested keys are &quot;text&quot;, &quot;author&quot;, and &quot;date&quot;. For better generation quality, it is recommended to keep the total word count of the strings in the dictionary to under 300 words.</p>
         * <p>An <code>id</code> field (string) can be optionally supplied to identify the document in the citations. This field will not be passed to the model.</p>
         * <p>An <code>_excludes</code> field (array of strings) can be optionally supplied to omit some key-value pairs from being shown to the model. The omitted fields will still show up in the citation object. The &quot;_excludes&quot; field will not be passed to the model.</p>
         * <p>See <a href="https://docs.cohere.com/docs/retrieval-augmented-generation-rag#document-mode">'Document Mode'</a> in the guide for more information.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage documents(List<Map<String, String>> documents) {
            this.documents = Optional.ofNullable(documents);
            return this;
        }

        /**
         * <p>A list of relevant documents that the model can cite to generate a more accurate reply. Each document is a string-string dictionary.</p>
         * <p>Example:</p>
         * <pre><code>[
         *   { &quot;title&quot;: &quot;Tall penguins&quot;, &quot;text&quot;: &quot;Emperor penguins are the tallest.&quot; },
         *   { &quot;title&quot;: &quot;Penguin habitats&quot;, &quot;text&quot;: &quot;Emperor penguins only live in Antarctica.&quot; },
         * ]
         * </code></pre>
         * <p>Keys and values from each document will be serialized to a string and passed to the model. The resulting generation will include citations that reference some of these documents.</p>
         * <p>Some suggested keys are &quot;text&quot;, &quot;author&quot;, and &quot;date&quot;. For better generation quality, it is recommended to keep the total word count of the strings in the dictionary to under 300 words.</p>
         * <p>An <code>id</code> field (string) can be optionally supplied to identify the document in the citations. This field will not be passed to the model.</p>
         * <p>An <code>_excludes</code> field (array of strings) can be optionally supplied to omit some key-value pairs from being shown to the model. The omitted fields will still show up in the citation object. The &quot;_excludes&quot; field will not be passed to the model.</p>
         * <p>See <a href="https://docs.cohere.com/docs/retrieval-augmented-generation-rag#document-mode">'Document Mode'</a> in the guide for more information.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "documents", nulls = Nulls.SKIP)
        public _FinalStage documents(Optional<List<Map<String, String>>> documents) {
            this.documents = documents;
            return this;
        }

        /**
         * <p>Defaults to <code>false</code>.</p>
         * <p>When <code>true</code>, the response will only contain a list of generated search queries, but no search will take place, and no reply from the model to the user's <code>message</code> will be generated.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage searchQueriesOnly(Boolean searchQueriesOnly) {
            this.searchQueriesOnly = Optional.ofNullable(searchQueriesOnly);
            return this;
        }

        /**
         * <p>Defaults to <code>false</code>.</p>
         * <p>When <code>true</code>, the response will only contain a list of generated search queries, but no search will take place, and no reply from the model to the user's <code>message</code> will be generated.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "search_queries_only", nulls = Nulls.SKIP)
        public _FinalStage searchQueriesOnly(Optional<Boolean> searchQueriesOnly) {
            this.searchQueriesOnly = searchQueriesOnly;
            return this;
        }

        /**
         * <p>Accepts <code>{&quot;id&quot;: &quot;web-search&quot;}</code>, and/or the <code>&quot;id&quot;</code> for a custom <a href="https://docs.cohere.com/docs/connectors">connector</a>, if you've <a href="https://docs.cohere.com/v1/docs/creating-and-deploying-a-connector">created</a> one.</p>
         * <p>When specified, the model's reply will be enriched with information found by querying each of the connectors (RAG).</p>
         * <p>Compatible Deployments: Cohere Platform</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage connectors(List<ChatConnector> connectors) {
            this.connectors = Optional.ofNullable(connectors);
            return this;
        }

        /**
         * <p>Accepts <code>{&quot;id&quot;: &quot;web-search&quot;}</code>, and/or the <code>&quot;id&quot;</code> for a custom <a href="https://docs.cohere.com/docs/connectors">connector</a>, if you've <a href="https://docs.cohere.com/v1/docs/creating-and-deploying-a-connector">created</a> one.</p>
         * <p>When specified, the model's reply will be enriched with information found by querying each of the connectors (RAG).</p>
         * <p>Compatible Deployments: Cohere Platform</p>
         */
        @java.lang.Override
        @JsonSetter(value = "connectors", nulls = Nulls.SKIP)
        public _FinalStage connectors(Optional<List<ChatConnector>> connectors) {
            this.connectors = connectors;
            return this;
        }

        /**
         * <p>Defaults to <code>AUTO</code> when <code>connectors</code> are specified and <code>OFF</code> in all other cases.</p>
         * <p>Dictates how the prompt will be constructed.</p>
         * <p>With <code>prompt_truncation</code> set to &quot;AUTO&quot;, some elements from <code>chat_history</code> and <code>documents</code> will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be changed and ranked by relevance.</p>
         * <p>With <code>prompt_truncation</code> set to &quot;AUTO_PRESERVE_ORDER&quot;, some elements from <code>chat_history</code> and <code>documents</code> will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be preserved as they are inputted into the API.</p>
         * <p>With <code>prompt_truncation</code> set to &quot;OFF&quot;, no elements will be dropped. If the sum of the inputs exceeds the model's context length limit, a <code>TooManyTokens</code> error will be returned.</p>
         * <p>Compatible Deployments:</p>
         * <ul>
         * <li>AUTO: Cohere Platform Only</li>
         * <li>AUTO_PRESERVE_ORDER: Azure, AWS Sagemaker/Bedrock, Private Deployments</li>
         * </ul>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage promptTruncation(ChatRequestPromptTruncation promptTruncation) {
            this.promptTruncation = Optional.ofNullable(promptTruncation);
            return this;
        }

        /**
         * <p>Defaults to <code>AUTO</code> when <code>connectors</code> are specified and <code>OFF</code> in all other cases.</p>
         * <p>Dictates how the prompt will be constructed.</p>
         * <p>With <code>prompt_truncation</code> set to &quot;AUTO&quot;, some elements from <code>chat_history</code> and <code>documents</code> will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be changed and ranked by relevance.</p>
         * <p>With <code>prompt_truncation</code> set to &quot;AUTO_PRESERVE_ORDER&quot;, some elements from <code>chat_history</code> and <code>documents</code> will be dropped in an attempt to construct a prompt that fits within the model's context length limit. During this process the order of the documents and chat history will be preserved as they are inputted into the API.</p>
         * <p>With <code>prompt_truncation</code> set to &quot;OFF&quot;, no elements will be dropped. If the sum of the inputs exceeds the model's context length limit, a <code>TooManyTokens</code> error will be returned.</p>
         * <p>Compatible Deployments:</p>
         * <ul>
         * <li>AUTO: Cohere Platform Only</li>
         * <li>AUTO_PRESERVE_ORDER: Azure, AWS Sagemaker/Bedrock, Private Deployments</li>
         * </ul>
         */
        @java.lang.Override
        @JsonSetter(value = "prompt_truncation", nulls = Nulls.SKIP)
        public _FinalStage promptTruncation(Optional<ChatRequestPromptTruncation> promptTruncation) {
            this.promptTruncation = promptTruncation;
            return this;
        }

        /**
         * <p>An alternative to <code>chat_history</code>.</p>
         * <p>Providing a <code>conversation_id</code> creates or resumes a persisted conversation with the specified ID. The ID can be any non empty string.</p>
         * <p>Compatible Deployments: Cohere Platform</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage conversationId(String conversationId) {
            this.conversationId = Optional.ofNullable(conversationId);
            return this;
        }

        /**
         * <p>An alternative to <code>chat_history</code>.</p>
         * <p>Providing a <code>conversation_id</code> creates or resumes a persisted conversation with the specified ID. The ID can be any non empty string.</p>
         * <p>Compatible Deployments: Cohere Platform</p>
         */
        @java.lang.Override
        @JsonSetter(value = "conversation_id", nulls = Nulls.SKIP)
        public _FinalStage conversationId(Optional<String> conversationId) {
            this.conversationId = conversationId;
            return this;
        }

        /**
         * <p>A list of previous messages between the user and the model, giving the model conversational context for responding to the user's <code>message</code>.</p>
         * <p>Each item represents a single message in the chat history, excluding the current user turn. It has two properties: <code>role</code> and <code>message</code>. The <code>role</code> identifies the sender (<code>CHATBOT</code>, <code>SYSTEM</code>, or <code>USER</code>), while the <code>message</code> contains the text content.</p>
         * <p>The chat_history parameter should not be used for <code>SYSTEM</code> messages in most cases. Instead, to add a <code>SYSTEM</code> role message at the beginning of a conversation, the <code>preamble</code> parameter should be used.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage chatHistory(List<Message> chatHistory) {
            this.chatHistory = Optional.ofNullable(chatHistory);
            return this;
        }

        /**
         * <p>A list of previous messages between the user and the model, giving the model conversational context for responding to the user's <code>message</code>.</p>
         * <p>Each item represents a single message in the chat history, excluding the current user turn. It has two properties: <code>role</code> and <code>message</code>. The <code>role</code> identifies the sender (<code>CHATBOT</code>, <code>SYSTEM</code>, or <code>USER</code>), while the <code>message</code> contains the text content.</p>
         * <p>The chat_history parameter should not be used for <code>SYSTEM</code> messages in most cases. Instead, to add a <code>SYSTEM</code> role message at the beginning of a conversation, the <code>preamble</code> parameter should be used.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "chat_history", nulls = Nulls.SKIP)
        public _FinalStage chatHistory(Optional<List<Message>> chatHistory) {
            this.chatHistory = chatHistory;
            return this;
        }

        /**
         * <p>When specified, the default Cohere preamble will be replaced with the provided one. Preambles are a part of the prompt used to adjust the model's overall behavior and conversation style, and use the <code>SYSTEM</code> role.</p>
         * <p>The <code>SYSTEM</code> role is also used for the contents of the optional <code>chat_history=</code> parameter. When used with the <code>chat_history=</code> parameter it adds content throughout a conversation. Conversely, when used with the <code>preamble=</code> parameter it adds content at the start of the conversation only.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage preamble(String preamble) {
            this.preamble = Optional.ofNullable(preamble);
            return this;
        }

        /**
         * <p>When specified, the default Cohere preamble will be replaced with the provided one. Preambles are a part of the prompt used to adjust the model's overall behavior and conversation style, and use the <code>SYSTEM</code> role.</p>
         * <p>The <code>SYSTEM</code> role is also used for the contents of the optional <code>chat_history=</code> parameter. When used with the <code>chat_history=</code> parameter it adds content throughout a conversation. Conversely, when used with the <code>preamble=</code> parameter it adds content at the start of the conversation only.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "preamble", nulls = Nulls.SKIP)
        public _FinalStage preamble(Optional<String> preamble) {
            this.preamble = preamble;
            return this;
        }

        /**
         * <p>The name of a compatible <a href="https://docs.cohere.com/docs/models">Cohere model</a> or the ID of a <a href="https://docs.cohere.com/docs/chat-fine-tuning">fine-tuned</a> model.</p>
         * <p>Compatible Deployments: Cohere Platform, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage model(String model) {
            this.model = Optional.ofNullable(model);
            return this;
        }

        /**
         * <p>The name of a compatible <a href="https://docs.cohere.com/docs/models">Cohere model</a> or the ID of a <a href="https://docs.cohere.com/docs/chat-fine-tuning">fine-tuned</a> model.</p>
         * <p>Compatible Deployments: Cohere Platform, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "model", nulls = Nulls.SKIP)
        public _FinalStage model(Optional<String> model) {
            this.model = model;
            return this;
        }

        /**
         * <p>When enabled, the user's prompt will be sent to the model without
         * any pre-processing.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage rawPrompting(Boolean rawPrompting) {
            this.rawPrompting = Optional.ofNullable(rawPrompting);
            return this;
        }

        /**
         * <p>When enabled, the user's prompt will be sent to the model without
         * any pre-processing.</p>
         * <p>Compatible Deployments: Cohere Platform, Azure, AWS Sagemaker/Bedrock, Private Deployments</p>
         */
        @java.lang.Override
        @JsonSetter(value = "raw_prompting", nulls = Nulls.SKIP)
        public _FinalStage rawPrompting(Optional<Boolean> rawPrompting) {
            this.rawPrompting = rawPrompting;
            return this;
        }

        /**
         * <p>Pass text/event-stream to receive the streamed response as server-sent events. The default is <code>\n</code> delimited events.</p>
         * @return Reference to {@code this} so that method calls can be chained together.
         */
        @java.lang.Override
        public _FinalStage accepts(String accepts) {
            this.accepts = Optional.ofNullable(accepts);
            return this;
        }

        /**
         * <p>Pass text/event-stream to receive the streamed response as server-sent events. The default is <code>\n</code> delimited events.</p>
         */
        @java.lang.Override
        @JsonSetter(value = "Accepts", nulls = Nulls.SKIP)
        public _FinalStage accepts(Optional<String> accepts) {
            this.accepts = accepts;
            return this;
        }

        @java.lang.Override
        public ChatRequest build() {
            return new ChatRequest(
                    accepts,
                    rawPrompting,
                    message,
                    model,
                    preamble,
                    chatHistory,
                    conversationId,
                    promptTruncation,
                    connectors,
                    searchQueriesOnly,
                    documents,
                    citationQuality,
                    temperature,
                    maxTokens,
                    maxInputTokens,
                    k,
                    p,
                    seed,
                    stopSequences,
                    frequencyPenalty,
                    presencePenalty,
                    tools,
                    toolResults,
                    forceSingleStep,
                    responseFormat,
                    safetyMode,
                    additionalProperties);
        }
    }
}
